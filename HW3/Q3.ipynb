{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mvajhi/unsupervised-learning/blob/master/HW3/Q3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HqgcmKih-qFV"
      },
      "source": [
        "# Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "transform = torchvision.transforms.ToTensor()\n",
        "mnist_trainset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "mnist_testset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
        "\n",
        "print('length of the training set: {}'.format(len(mnist_trainset)))\n",
        "print('length of the test set: {}'.format(len(mnist_testset)))\n",
        "\n",
        "\n",
        "figure = plt.figure(figsize=(10, 5))\n",
        "cols, rows = 5, 2\n",
        "displayed_labels = []\n",
        "\n",
        "for img, label in mnist_trainset:\n",
        "    if len(displayed_labels) == 10:\n",
        "        break\n",
        "    if label not in displayed_labels:\n",
        "        ax = figure.add_subplot(rows, cols, len(displayed_labels) + 1)\n",
        "        ax.set_title((label))\n",
        "        ax.axis(\"off\")\n",
        "        plt.imshow(img.squeeze(), cmap=\"gray\")\n",
        "        displayed_labels.append(label)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OobZW47yHQdz",
        "outputId": "05cf815f-9ac3-4401-ad33-3e9ad853f475",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        }
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9.91M/9.91M [00:00<00:00, 21.0MB/s]\n",
            "100%|██████████| 28.9k/28.9k [00:00<00:00, 614kB/s]\n",
            "100%|██████████| 1.65M/1.65M [00:00<00:00, 5.67MB/s]\n",
            "100%|██████████| 4.54k/4.54k [00:00<00:00, 4.53MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "length of the training set: 60000\n",
            "length of the test set: 10000\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 10 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAGBCAYAAAAOvKzFAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAMuJJREFUeJzt3XucjfX6//FrnMdhZBgiMdqMysRIctgM5VCpKOcix5JkHDbSQZI2nVSbDjqjmpIopOSQY04R2hsbk3KaQc7DMDOM+f3xe2z7e6/rs5u7Nesz96xZr+fjsf/4vPuse65dd2tcrXXdn7Ds7OxsAQAAAIAAK+R1AQAAAAAKJpoNAAAAAFbQbAAAAACwgmYDAAAAgBU0GwAAAACsoNkAAAAAYAXNBgAAAAAraDYAAAAAWEGzAQAAAMAKmg0AAAAAVtBsuLBixQoJCwsz/m/9+vVel4cQkJGRIaNHj5YqVapIeHi4NGrUSJYsWeJ1WQhREyZMkLCwMImNjfW6FISAs2fPyjPPPCO33367REZGSlhYmEyfPt3rshBCfvrpJ7n99tslIiJCypQpI23btpWtW7d6XVbQKOJ1AcFkyJAh0rBhQ0dWs2ZNj6pBKOnTp4/Mnj1bhg0bJrVq1ZLp06dLu3btZPny5dKsWTOvy0MIOXjwoEycOFFKlSrldSkIEceOHZPx48dLtWrVpF69erJixQqvS0II2bx5szRr1kyuvvpqeeaZZ+TSpUvy1ltvSYsWLeTHH3+U2rVre11ivheWnZ2d7XUR+d2KFSvklltukS+++EI6d+7sdTkIMT/++KM0atRIXn75ZRk5cqSIiKSnp0tsbKxUrFhR1q5d63GFCCXdu3eXo0ePSlZWlhw7dky2bdvmdUko4DIyMuTkyZNy5ZVXyqZNm6Rhw4Yybdo06dOnj9elIQTceeedsm7dOklKSpLy5cuLiMihQ4ckJiZG2rZtK3PmzPG4wvyPr1H9SWfOnJGLFy96XQZCyOzZs6Vw4cIyYMCAy1mJEiWkf//+sm7dOjlw4ICH1SGUrFq1SmbPni3/+Mc/vC4FIaR48eJy5ZVXel0GQtTq1auldevWlxsNEZHKlStLixYtZMGCBXL27FkPqwsONBt/Qt++fSUiIkJKlCght9xyi2zatMnrkhACtmzZIjExMRIREeHIb775ZhERvjeKPJGVlSUJCQny4IMPyg033OB1OQCQJzIyMiQ8PFzlJUuWlMzMTD7ddYGZDReKFSsmnTp1knbt2kmFChVkx44dMmnSJGnevLmsXbtW6tev73WJKMAOHToklStXVvl/spSUlLwuCSHo7bffln379snSpUu9LgUA8kzt2rVl/fr1kpWVJYULFxYRkczMTNmwYYOIiCQnJ3tZXlDgkw0XmjZtKrNnz5Z+/fpJ+/bt5fHHH5f169dLWFiYPPHEE16XhwLu/PnzUrx4cZWXKFHi8l8HbDp+/LiMHTtWnn76aYmKivK6HADIM4MGDZLdu3dL//79ZceOHbJt2zbp1auXHDp0SET4HewGzYafatasKR06dJDly5dLVlaW1+WgAAsPD5eMjAyVp6enX/7rgE1jxoyRyMhISUhI8LoUAMhTAwcOlCeffFI+/fRTqVOnjtxwww2yZ88eeeyxx0REpHTp0h5XmP/RbOTC1VdfLZmZmZKWluZ1KSjAKleufPm/oPxf/8mqVKmS1yUhhCQlJcm7774rQ4YMkZSUFNm7d6/s3btX0tPT5cKFC7J37145ceKE12UCgDUTJkyQI0eOyOrVq+Wf//ynbNy4US5duiQiIjExMR5Xl//RbOTCr7/+KiVKlKCrhVVxcXGye/duSU1NdeT/+b5oXFycB1UhVCQnJ8ulS5dkyJAhUqNGjcv/27Bhg+zevVtq1Kgh48eP97pMALCqXLly0qxZs8sPyFi6dKlUrVpVrr32Wo8ry/8YEHfh6NGj6nvKP//8s8yfP1/uuOMOKVSIng32dO7cWSZNmiTvvvvu5XM2MjIyZNq0adKoUSO5+uqrPa4QBVlsbKx89dVXKh8zZoycOXNGJk+eLH/5y188qAwAvPH555/Lxo0bZdKkSfwZ0AUO9XPh1ltvlfDwcGnatKlUrFhRduzYIe+++64ULVpU1q1bJ9ddd53XJaKA69q1q3z11VcyfPhwqVmzpsyYMUN+/PFH+f777yU+Pt7r8hCCWrZsyaF+yDNvvPGGnDp1SlJSUmTq1KnSsWPHy0+CTEhIkLJly3pcIQqqVatWyfjx46Vt27ZSvnx5Wb9+vUybNk3atGkjX3/9tRQpwn+3zwnNhgtTpkyRxMRE+eWXXyQ1NVWioqKkVatW8swzz0jNmjW9Lg8hID09XZ5++mn55JNP5OTJk1K3bl157rnn5LbbbvO6NIQomg3kpejoaNm3b5/xr/32228SHR2dtwUhZOzZs0cGDRokmzdvljNnzkiNGjWkd+/e8re//U2KFSvmdXlBgWYDAAAAgBV80QwAAACAFTQbAAAAAKyg2QAAAABgBc0GAAAAACtoNgAAAABYQbMBAAAAwArXJ5GEhYXZrANBKq+enMz9B5O8fHI39yBMeA+El7j/4CW39x+fbAAAAACwgmYDAAAAgBU0GwAAAACsoNkAAAAAYAXNBgAAAAAraDYAAAAAWEGzAQAAAMAKmg0AAAAAVtBsAAAAALCCZgMAAACAFTQbAAAAAKyg2QAAAABgBc0GAAAAACtoNgAAAABYQbMBAAAAwAqaDQAAAABW0GwAAAAAsIJmAwAAAIAVRbwuAEDuNWjQQGWDBw92rHv16qX2fPTRRyp7/fXXVbZ58+ZcVAcAAEIVn2wAAAAAsIJmAwAAAIAVNBsAAAAArKDZAAAAAGBFWHZ2drarjWFhtmvxXOHChVVWtmxZv6/nO6BbsmRJtad27doqe/TRR1U2adIkx/q+++5Te9LT01X2wgsvqOzZZ5/VxfrJ5e2Ta6Fw/7kVFxensmXLlqksIiLCr+ufPn1aZeXLl/frWrbl1f0nwj3otVatWjnWiYmJak+LFi1UtmvXLms1ifAeGOzGjBmjMtPvyEKFnP9ttmXLlmrPypUrA1aXW9x/8JLb+49PNgAAAABYQbMBAAAAwAqaDQAAAABW0GwAAAAAsCLoTxCvVq2ayooVK6aypk2bqqxZs2aO9RVXXKH2dOrUyf/iXDh48KDKpkyZorJ7773XsT5z5oza8/PPP6vMi4E1BM7NN9+ssjlz5qjM9CAD38Et0z2TmZmpMtMweOPGjR1r04nipmvBLD4+XmWmv+9fffVVXpQTFBo2bOhYb9y40aNKEKz69OmjstGjR6vs0qVLOV4rLx9OAQQ7PtkAAAAAYAXNBgAAAAAraDYAAAAAWBFUMxtuDzPLzUF8Npm+B2o6UOjs2bMq8z3A6tChQ2rPyZMnVWb7QCv4z/eQxxtvvFHt+eSTT1RWuXJlv35eUlKSyl566SWVzZw5U2Vr1qxxrE337fPPP+9XXaHIdCBYrVq1VBaqMxu+B6iJiNSoUcOxrl69utrDwWP4I6Z7pkSJEh5UgvyoUaNGKuvZs6fKTIeH1qlTJ8frjxw5UmUpKSkq850nFtF/FtiwYUOOPy8/4ZMNAAAAAFbQbAAAAACwgmYDAAAAgBU0GwAAAACsCKoB8f3796vs+PHjKrM9IG4azDl16pTKbrnlFsfadOjZxx9/HLC6EFzeeecdx/q+++6z+vNMA+ilS5dWmekgSN+B5rp16wasrlDUq1cvla1bt86DSvIn00MQHnroIcfa9PCEnTt3WqsJwad169aOdUJCgqvXme6ju+66y7E+cuSI/4UhX+jWrZtjPXnyZLWnQoUKKjM9iGLFihUqi4qKcqxffvllV3WZru97re7du7u6Vn7BJxsAAAAArKDZAAAAAGAFzQYAAAAAK2g2AAAAAFgRVAPiJ06cUNmoUaNU5jvIJSKyZcsWlU2ZMiXHn7l161aVtWnTRmVpaWkq8z1RcujQoTn+PBRMDRo0UNmdd97pWLs9/dg0wP3111+rbNKkSY616aRS078XppPob731Vseak5pzx3RCNv7r/fffz3FPUlJSHlSCYGE6dXnatGmOtduHx5gGefft2+dfYchzRYroP9redNNNKnvvvfcc65IlS6o9q1atUtlzzz2nsh9++EFlxYsXd6xnzZql9rRt21ZlJps2bXK1L7/iNx4AAAAAK2g2AAAAAFhBswEAAADACpoNAAAAAFYE1YC4ydy5c1W2bNkylZ05c0Zl9erVc6z79++v9vgO2YqYh8FNtm/f7lgPGDDA1esQ3OLi4lS2ZMkSlUVERDjW2dnZas/ChQtVZjppvEWLFiobM2aMY20auj169KjKfv75Z5VdunTJsfYdbhcxn1C+efNmlYUa02nrlSpV8qCS4OFmkNf07xRCV+/evVVWpUqVHF9nOvn5o48+CkRJ8EjPnj1V5uahE6b3FN9TxkVEUlNTXdXh+1q3w+AHDx5U2YwZM1y9Nr/ikw0AAAAAVtBsAAAAALCCZgMAAACAFTQbAAAAAKwI+gFxE7fDO6dPn85xz0MPPaSyzz//XGW+A7QIDTExMSoznWpvGng9duyYY33o0CG1xzQUdvbsWZV98803rrJACQ8PV9mIESNU1qNHD2s1BIt27dqpzPT3L1SZhuVr1KiR4+uSk5NtlIMgUKFCBZX169dPZb6/l0+dOqX2/P3vfw9YXch7ptO8n3zySZWZHsDy1ltvOda+D1URcf/nSZOnnnrKr9cNGTJEZaaHuQQTPtkAAAAAYAXNBgAAAAAraDYAAAAAWFEgZzbcGjdunGPdoEEDtcd0WFrr1q1Vtnjx4oDVhfypePHiKjMd+mj6jr7pUMlevXo51ps2bVJ7gum7/dWqVfO6hHypdu3arvb5HgIaKkz/DpnmOHbv3u1Ym/6dQsETHR2tsjlz5vh1rddff11ly5cv9+tayHtjx45VmWk+IzMzU2WLFi1S2ejRox3r8+fPu6qjRIkSKjMd2Of7OzEsLEztMc0MzZs3z1UdwYRPNgAAAABYQbMBAAAAwAqaDQAAAABW0GwAAAAAsCKkB8TT0tIca9MBfps3b1bZe++9pzLTkJnvwO+bb76p9pgOmkH+VL9+fZWZhsFNOnTooLKVK1fmuiYUHBs3bvS6hFyJiIhQ2e233+5Y9+zZU+0xDVaa+B7eZTqgDQWP7z0kIlK3bl1Xr/3+++8d68mTJwekJuSNK664wrEeNGiQ2mP6M5RpGPyee+7xq4aaNWuqLDExUWWmBwz5mj17tspeeuklv+oKNnyyAQAAAMAKmg0AAAAAVtBsAAAAALCCZgMAAACAFSE9IO5rz549KuvTp4/Kpk2bprIHHnggx6xUqVJqz0cffaSyQ4cO/VGZ8Mirr76qMtOJoKbB72AfBi9UyPnfJS5duuRRJQVXZGRkwK5Vr149lZnu1datWzvWVatWVXuKFSumsh49eqjM9x4R0SfybtiwQe3JyMhQWZEi+lfTTz/9pDIULKYh3hdeeMHVa3/44QeV9e7d27E+ffq0X3XBG77vPRUqVHD1uiFDhqisYsWKKuvbt69j3b59e7UnNjZWZaVLl1aZaVDdN/vkk0/UHt8HFRVUfLIBAAAAwAqaDQAAAABW0GwAAAAAsIJmAwAAAIAVDIjn4KuvvlJZUlKSykzDw61atXKsJ06cqPZUr15dZRMmTFBZcnLyH9aJwLvrrrsc67i4OLXHNBQ2f/58WyV5xncg3PT/e+vWrXlUTXDxHZIWMf/9e/vtt1X25JNP+vUzTScsmwbEL1686FifO3dO7dmxY4fKPvzwQ5Vt2rRJZb4PRjhy5Ijac/DgQZWFh4erbOfOnSpDcIuOjnas58yZ4/e1fv31V5WZ7jcEj8zMTMf66NGjak9UVJTKfvvtN5WZ3nPdSElJUVlqaqrKKleurLJjx4451l9//bVfNRQEfLIBAAAAwAqaDQAAAABW0GwAAAAAsIJmAwAAAIAVDIj7Ydu2bSrr2rWryu6++27H2nTy+MMPP6yyWrVqqaxNmzZ/pkQEgO+Qqukk5d9//11ln3/+ubWaAq148eIqGzduXI6vW7ZsmcqeeOKJQJRU4AwaNEhl+/btU1nTpk0D9jP379+vsrlz56rs3//+t2O9fv36gNVgMmDAAJWZBjxNw74oeEaPHu1Y+z6I4s9we9I4gsepU6cca9MJ8wsWLFBZZGSkyvbs2aOyefPmOdbTp09Xe06cOKGymTNnqsw0IG7aF6r4ZAMAAACAFTQbAAAAAKyg2QAAAABgBTMbAeL73UIRkY8//tixfv/999WeIkX0P4L4+HiVtWzZ0rFesWLFn6oPdmRkZKjs0KFDHlSSM9N8xpgxY1Q2atQolfkevPbKK6+oPWfPns1FdaHlxRdf9LoET/gedPq/5OZwN+RPpkNR27Zt69e1fL9rLyKya9cuv66F4LFhwwaVmWa+Asn057EWLVqozDRvxOzZf/HJBgAAAAAraDYAAAAAWEGzAQAAAMAKmg0AAAAAVjAg7oe6deuqrHPnzipr2LChY20aBjfZsWOHylatWuWyOuSl+fPne13C/+Q7kGka/O7WrZvKTMOXnTp1ClhdQE6++uorr0tAgC1evFhl5cqVy/F1poMm+/TpE4iSgBz5Hu4rYh4Gz87OVhmH+v0Xn2wAAAAAsIJmAwAAAIAVNBsAAAAArKDZAAAAAGAFA+L/R+3atVU2ePBglXXs2FFlV155pV8/MysrS2WmE6hNA0mwKyws7A/XIiL33HOPyoYOHWqrpP9p+PDhKnv66acd67Jly6o9iYmJKuvVq1fgCgMAESlfvrzK3Pxee+utt1R29uzZgNQE5GTRokVel1Ag8MkGAAAAACtoNgAAAABYQbMBAAAAwAqaDQAAAABWhMyAuGmA+7777nOsTcPg0dHRAath06ZNKpswYYLK8vOp1KHE90RQ0wmhpvtqypQpKvvwww9Vdvz4cce6cePGas8DDzygsnr16qmsatWqKtu/f79jbRp0Mw1fAnnJ9OCFmJgYlZlOkkb+NG3aNJUVKuTff9tcu3ZtbssB/Hbbbbd5XUKBwCcbAAAAAKyg2QAAAABgBc0GAAAAACuCfmajUqVKKrv++utV9sYbb6js2muvDVgdGzZsUNnLL7/sWM+bN0/t4bC+4Fa4cGGVDRo0SGWdOnVSWWpqqmNdq1Ytv+swfa95+fLljvXYsWP9vj5gi2kWyt/v9yPvxcXFqax169YqM/2uy8zMdKzffPNNtefIkSP+Fwfk0jXXXON1CQUC7+gAAAAArKDZAAAAAGAFzQYAAAAAK2g2AAAAAFiRrwfEIyMjHet33nlH7TENpwVyoMc0ePvKK6+ozHRg2vnz5wNWB/LeunXrHOuNGzeqPQ0bNnR1LdPhf6aHG/jyPfhPRGTmzJkqGzp0qKs6gGDQpEkTlU2fPj3vC0GOrrjiCpWZ3u9MkpOTHeuRI0cGoiQgYFavXq0y0wMseNjPH+OTDQAAAABW0GwAAAAAsIJmAwAAAIAVNBsAAAAArPBkQLxRo0YqGzVqlMpuvvlmx/qqq64KaB3nzp1zrKdMmaL2TJw4UWVpaWkBrQP508GDBx3rjh07qj0PP/ywysaMGePXz5s8ebLKpk6dqrJffvnFr+sD+VFYWJjXJQCA0bZt21SWlJSkMtODif7yl7841kePHg1cYUGGTzYAAAAAWEGzAQAAAMAKmg0AAAAAVtBsAAAAALDCkwHxe++911Xmxo4dO1S2YMEClV28eFFlvieBnzp1yq8aEBoOHTqksnHjxrnKAIgsXLhQZV26dPGgEgTKzp07VbZ27VqVNWvWLC/KAawzPTjo/fffV9mECRMc64SEBLXH9GfYgohPNgAAAABYQbMBAAAAwAqaDQAAAABW0GwAAAAAsCIsOzs729VGTnmFgcvbJ9e4/2CSV/efCPcgzHgPhJe4//JeRESEymbNmqWy1q1bO9Zffvml2tO3b1+VpaWl5aK6vOX2/uOTDQAAAABW0GwAAAAAsIJmAwAAAIAVzGwgV/i+KLzEzAa8xnsgvMT9lz+Y5jh8D/V75JFH1J66deuqLJgO+mNmAwAAAICnaDYAAAAAWEGzAQAAAMAKmg0AAAAAVjAgjlxhOA1eYkAcXuM9EF7i/oOXGBAHAAAA4CmaDQAAAABW0GwAAAAAsIJmAwAAAIAVrgfEAQAAAODP4JMNAAAAAFbQbAAAAACwgmYDAAAAgBU0GwAAAACsoNkAAAAAYAXNBgAAAAAraDYAAAAAWEGzAQAAAMAKmg0AAAAAVtBsAAAAALCCZgMAAACAFTQbAAAAAKyg2QAAAABgBc0GAAAAACtoNgAAAABYQbMBAAAAwAqaDQAAAABW0GwAAAAAsIJmAwAAAIAVNBsAAAAArKDZAAAAAGAFzQYAAAAAK2g2AAAAAFhBswEAAADACpoNAAAAAFbQbAAAAACwgmYDAAAAgBU0GwAAAACsoNkAAAAAYAXNBgAAAAAraDYAAAAAWEGzAQAAAMAKmg0AAAAAVtBsAAAAALCCZgMAAACAFTQbAAAAAKyg2QAAAABgBc0GAAAAACtoNgAAAABYQbMBAAAAwAqaDQAAAABW0GwAAAAAsIJmAwAAAIAVNBsAAAAArKDZAAAAAGAFzQYAAAAAK2g2AAAAAFhBswEAAADACpoNAAAAAFbQbAAAAACwgmYDAAAAgBU0GwAAAACsoNkAAAAAYAXNBgAAAAAraDYAAAAAWEGz4cLGjRtl8ODBUqdOHSlVqpRUq1ZNunbtKrt37/a6NISA7du3S5cuXeSaa66RkiVLSoUKFSQ+Pl6+/vprr0tDCNm8ebO0b99eIiMjpWTJkhIbGytTpkzxuiyEgD59+khYWNj//F9ycrLXJaKAS0pKku7du0vVqlWlZMmScu2118r48ePl3LlzXpcWFMKys7OzvS4iv+vcubOsWbNGunTpInXr1pXDhw/LG2+8IWfPnpX169dLbGys1yWiAPv2229lypQp0qRJE6lSpYqcO3dO5syZI6tXr5Z33nlHBgwY4HWJKOAWL14sd999t9SvX1+6desmpUuXlj179silS5fkpZde8ro8FHDr1q2TPXv2OLLs7GwZOHCgREdHy/bt2z2qDKHgwIEDUrduXSlbtqwMHDhQIiMjZd26dTJ9+nRp3769zJs3z+sS8z2aDRfWrl0rN910kxQrVuxylpSUJDfccIN07txZPvnkEw+rQyjKysqSBg0aSHp6uuzcudPrclCApaamSkxMjDRt2lRmz54thQrxgTi898MPP0jz5s1lwoQJ8uSTT3pdDgqwiRMnylNPPSXbtm2TOnXqXM579+4tH330kZw4cULKlSvnYYX5H781XGjatKmj0RARqVWrltSpU0f+/e9/e1QVQlnhwoXl6quvllOnTnldCgq4Tz/9VI4cOSITJkyQQoUKSVpamly6dMnrshDiPv30UwkLC5P777/f61JQwKWmpoqISKVKlRx55cqVpVChQurPh9BoNvyUnZ0tR44ckQoVKnhdCkJEWlqaHDt2TPbs2SOvvfaaLFy4UFq1auV1WSjgli5dKhEREZKcnCy1a9eW0qVLS0REhDzyyCOSnp7udXkIQRcuXJBZs2ZJ06ZNJTo62utyUMC1bNlSRET69+8vW7dulQMHDsjnn38uU6dOlSFDhkipUqW8LTAI0Gz4KTExUZKTk6Vbt25el4IQMWLECImKipKaNWvKyJEj5d5775U33njD67JQwCUlJcnFixelQ4cOctttt8mcOXOkX79+8vbbb0vfvn29Lg8haNGiRXL8+HHp0aOH16UgBNx+++3y3HPPyZIlS6R+/fpSrVo16d69uyQkJMhrr73mdXlBoYjXBQSjnTt3yqOPPipNmjSR3r17e10OQsSwYcOkc+fOkpKSIrNmzZKsrCzJzMz0uiwUcGfPnpVz587JwIEDLz99qmPHjpKZmSnvvPOOjB8/XmrVquVxlQgln376qRQtWlS6du3qdSkIEdHR0RIfHy+dOnWS8uXLyzfffCMTJ06UK6+8UgYPHux1efkeA+J/0uHDh+Wvf/2rXLhwQdavXy9VqlTxuiSEqLZt28qpU6dkw4YNEhYW5nU5KKBiY2Nl+/btsnLlSomPj7+cr1q1Slq0aCEzZsyQXr16eVghQsnZs2elUqVKcuutt/L4b+SJmTNnSr9+/WT37t1StWrVy3nfvn1l1qxZsn//filfvryHFeZ/fI3qTzh9+rTccccdcurUKfnuu+9oNOCpzp07y8aNGznvBVb9533OdziyYsWKIiJy8uTJPK8JoWvu3Lly7tw5vkKFPPPWW29J/fr1HY2GiEj79u3l3LlzsmXLFo8qCx40Gy6lp6fL3XffLbt375YFCxbI9ddf73VJCHHnz58Xkf/fBAO2NGjQQEREHZyWkpIiIiJRUVF5XhNCV2JiopQuXVrat2/vdSkIEUeOHJGsrCyVX7hwQURELl68mNclBR2aDReysrKkW7dusm7dOvniiy+kSZMmXpeEEPL777+r7MKFC/LRRx9JeHg4jS+s+s/34j/44ANH/v7770uRIkUuP6kFsO3o0aOydOlSuffee6VkyZJel4MQERMTI1u2bFHfIvjss8+kUKFCUrduXY8qCx4MiLswYsQImT9/vtx9991y4sQJdYhfz549PaoMoeDhhx+W1NRUiY+Pl6uuukoOHz4siYmJsnPnTnnllVekdOnSXpeIAqx+/frSr18/+fDDD+XixYvSokULWbFihXzxxRfyxBNP8HVS5JnPP/9cLl68yFeokKdGjRolCxculObNm8vgwYOlfPnysmDBAlm4cKE8+OCDvAe6wIC4Cy1btpSVK1f+z7/O30LYNHPmTPnggw/kX//6lxw/flzKlCkjDRo0kISEBL5KgDxx4cIFmThxokybNk1SUlKkevXq8uijj8qwYcO8Lg0hpEmTJvLrr79KSkqKFC5c2OtyEEJ+/PFHGTdunGzZskWOHz8uNWrUkN69e8tjjz0mRYrw3+1zQrMBAAAAwApmNgAAAABYQbMBAAAAwAqaDQAAAABW0GwAAAAAsIJmAwAAAIAVNBsAAAAArHD9cOCwsDCbdSBI5dWTk7n/YJKXT+7mHoQJ74HwEvcfvOT2/uOTDQAAAABW0GwAAAAAsIJmAwAAAIAVNBsAAAAArKDZAAAAAGAFzQYAAAAAK2g2AAAAAFhBswEAAADACpoNAAAAAFa4PkEcAIA/IyYmxrH+7rvv1J7ChQurrHr16tZqAgDkLT7ZAAAAAGAFzQYAAAAAK2g2AAAAAFjBzAYAINdef/11lXXr1s2xjoyMVHsWLFhgrSYAgPf4ZAMAAACAFTQbAAAAAKyg2QAAAABgBc0GAAAAACvCsrOzs11tDAuzXQuCkMvbJ9e4/2CSV/efSOjeg5UqVVLZl19+qbLGjRurzPefz7Zt29SeVq1aqez48eN/pkRP8R4IL3H/wUtu7z8+2QAAAABgBc0GAAAAACtoNgAAAABYQbMBAAAAwApOEA+QMmXKqKx06dKO9Z133qn2REVFqezVV19VWUZGRi6qQ34UExPjWBctWlTtiY+PV9lbb72lskuXLgWuMIN58+Y51t27d1d7MjMzrdYA+3zvSRGRSZMmqaxRo0aurvfEE0841ps2bVJ7gmkYHABsK1WqlMpWrFjhWFepUkXt+etf/6qyvXv3BqqsXOGTDQAAAABW0GwAAAAAsIJmAwAAAIAVNBsAAAAArGBAPAfR0dEqGz16tMqaNGmistjYWL9+ZuXKlVU2ZMgQv66FvFenTh2V9enTR2VdunRxrAsV0r2/aQjMNAxu+xTZ9u3bO9Zvv/222jNs2DCVpaam2ioJFkRGRqqsXbt2fl/v4MGDjvXy5cv9vhYA5Fem39WmBwD5OnnypMpuueUWlTVo0MCx3rVrl9qTnx+2wScbAAAAAKyg2QAAAABgBc0GAAAAACvCsl1+2TssLMx2LXnu2muvdaxN3znv0aOHysLDw1Vm+vtz4MABx/rMmTNqz3XXXaeyY8eOqaxly5aO9c6dO9UeL9ieFfiPYLr/5s+fr7LcfO/dl+nvRV79c/gjLVq0UNmaNWus/sy8/P8dTPegW76H+H333XdqT/Xq1V1dq2PHjirzPQyyIOI9MH8YMWKEyooVK+ZYm37fmn7Hm/j+zjXN5nmB+89/vnO1ptlYt+9/pgNRq1WrluPrXnjhBZVdf/31Krvnnnsc6++//17t6datm8psz3G4vf/4ZAMAAACAFTQbAAAAAKyg2QAAAABgBc0GAAAAACsK5KF+ZcuWVdmLL76oMt9hmjJlyvj9M5OSklR22223OdZFixZVe0yD3hUqVHCVIX9asmSJytwMiP/+++8q++CDD1RmOvzPdNCfr6ZNm6rMNNSN0PHAAw841qaBxm+//VZlAwcOVFlycnLgCkNIMr0fmQ7HNe279957VeZmqNntgGutWrUc6x07dqg9psFe5F+33nqrY92/f3+/r5WRkaGyTz755A9/nojI448/7ur6vvfp9OnT1R4O9QMAAAAQcmg2AAAAAFhBswEAAADACpoNAAAAAFYUyAFx06DYgw8+GLDr79mzR2Vt2rRRme8J4jVr1gxYDci/pk6dqrK5c+fm+LoLFy6o7PDhw4EoSUREIiIiVLZt2zaVValSJcdrmf7/bNq0ya+6kDfWrl2rsri4OMd67969as/w4cNVxjA4/qNy5coq++yzz1R2zTXX5Hgt08NdSpUqpTLT4PdPP/2kshtvvDHHn+mW74M5THUh/xo3bpzKRo0alePrZsyYobKjR4+qbNKkSTnu832/FRFZtGiRykwPBPK91uzZs9We/IxPNgAAAABYQbMBAAAAwAqaDQAAAABW0GwAAAAAsKJADoh36dLFr9eZhiM3btyostGjR6vMdxjc5LrrrvOrLgSXixcvqszN/WGb74n2IiLlypXz61oHDx5UmekEVXijQ4cOKmvUqJHKfE+l/eKLL9Se9PT0wBWGoNa6dWuVvffeeyq7+uqrrdZhOqn72LFjKvMdtDU9/GLatGkqq1q1ao41mE4QR/5lGugPDw93rPft26f2PPXUUyo7dOiQq5/p+1CgJ598Uu2JiopSWVpamsp8B9yD7X2ZTzYAAAAAWEGzAQAAAMAKmg0AAAAAVtBsAAAAALCiQA6IP/TQQyobMGCAyhYvXuxY//LLL2rP77//HrC6KlWqFLBrATnp3r27Y23698J3QM6tsWPH+vU6BN4VV1yhsubNm/t1rZMnT6rM9DAAfw0dOlRlboeJR44cGbA64J/HHntMZbkZBvd9qITp4Svr169X2a5du1xd//jx44616f5zMwwuoh8g88ADD7h6HfIH04nbt99+u2NtevDACy+8oLJBgwaprGzZsip79dVXHes777xT7Tlx4oTKJkyYoLKpU6eqLJjwyQYAAAAAK2g2AAAAAFhBswEAAADAigI5s5GSkqIy3wNRvNCkSROvS0AB0KNHD5U9/vjjKvM9UKho0aJ+/8ytW7c61hcuXPD7WgisrKwslTVo0EBlhQrp/7Z06dIlx3rVqlV+1zF8+PAc9yQkJKisevXqrq4/YsQIx9r0Xfvk5GRX14I7bdu2dawbN27s97X279+vMt+5hzVr1vh9fTfczmeYzJs3z7E2HSKI/Mv3d5iIngcyzWzceuutKmvTpo3KXnvtNZVVq1Ytx7qeffZZlb3++us5vi7Y8MkGAAAAACtoNgAAAABYQbMBAAAAwAqaDQAAAABWFMgB8UAaMmSIykqVKuXXtW644QZX+9auXauydevW+fUzkfeio6NVZjoAqnXr1n5dv1mzZirLzs7261qpqakqMw2bf/vtt471+fPn/fp5CLwWLVqozHSon+8wuIge2nU79BoXF+fqZ7Zv3z7Ha6WlpanMdJBg7dq1HWvTIV2+B1mKiOzbty/HGmDmO5RfsmRJV68z/Q4zDcIGciC8XLlyKvM9tC0+Pt7VtUz1+74HIrj4HiApYv7956tKlSoqmzNnjsrCwsJU5vt7+YMPPlB75s6dm2MNBQGfbAAAAACwgmYDAAAAgBU0GwAAAACsoNkAAAAAYEXIDIibBtt8T4t85pln1J527dq5ur6b03lNTKed9+3bV2WmU4LhvdjYWJXNnz9fZW5OEvXC6tWrVfbuu+96UAncKFOmjMpq1Kjh6rWm95qPP/7Ysf7ll1/UnpiYGJWNGjVKZR06dFCZ78D54sWL1Z5XXnlFZWXLllXZsmXLctyDwPJ9L6hQoYLac/r0aZXdf//9Kjt8+HDgCjMYOHCgyp577rkcX7d9+3aVde3aVWW260fes/3wCN+HCkyaNEntOXDggNUa8gs+2QAAAABgBc0GAAAAACtoNgAAAABYQbMBAAAAwIqgHxAvWrSoyurXr68y04mPlStXdqxNpyKbhipNp3n7nlQq4u601SJF9D+Cjh07qmzy5MmOdWZmZo7XhjdMJ4maMn/5+zACk7vuuktld9xxh8oWLlzo1/URWKbT41977TVXr33vvfdUNn78eMe6UqVKao9pqNH04IwzZ86obNasWY71yJEj1Z5atWqp7O23387x+t9//73aw2nhgeX7e9P0e9QLd999t8rGjh2b4+suXryoMtO9xjB4wVO4cGGVNW/e3LHOze/pb775RmWm+zRU8ckGAAAAACtoNgAAAABYQbMBAAAAwAqaDQAAAABWBNWAeLFixVRmGsz+8ssvXV3v2Wefdax9T6gVEVmzZo3KIiMjVWZ6rel0aV9RUVEqe/7551W2f/9+x3ru3LlqT0ZGRo4/D4G1bds2lbVs2VJlPXv2VNmiRYsc6/T09IDVJSLSv39/xzohISGg10feq1u3rt+v9R0GNzG9dzZq1MjV9U0niK9cudKxbty4sdrzww8/uLr+P/7xD8faNGyO0GD6/ZednZ3j64YMGaIy31PSUTDNnDlTZb4P43FzD/0vuXltKOCTDQAAAABW0GwAAAAAsIJmAwAAAIAV+Xpmw/fAPt8ZCxGRUaNGubqW6VCy119/3bE+deqU2mOaqfj2229VdsMNN6jM9+C9l156Se0xzXWYvvucmJjoWC9dulTtefHFF1V28uRJlZls3brV1T7kzHSw2IQJE/K8jnHjxjnWzGwEvyuuuEJlpoOo5s2b5+p6cXFxjnV0dLSr648YMUJlvvMZIiIxMTGO9aeffur39X1nNhAaJk6cqDJ/DzY13aMIblWqVFFZ3759VdapUyeV+c5ZbN68We35+eefXV2/YsWKf1hnqOOTDQAAAABW0GwAAAAAsIJmAwAAAIAVNBsAAAAArMg3A+KFCxdW2XPPPedYmw5xSktLU9njjz+uMtOBLr4D4TfddJPa88Ybb6isfv36KktKSlLZI4884lgvX75c7YmIiFBZ06ZNVdajRw/Hun379mrPkiVLVGZy4MABldWoUcPVaxE8brvtNq9LQB4wHSbl7wFTpiFb07VMhwv6HjwqIlKiRAnH+rffflN7mjdvrrLTp0//YZ0omEwH95p+37q9T4cOHepYm35PI7i1atVKZW4OMBURGTNmjGNt+vPePffcozLTgPiOHTtc/cxQxScbAAAAAKyg2QAAAABgBc0GAAAAACtoNgAAAABYkW8GxAcMGKAy34Hwc+fOqT0PP/ywyhYvXqyyxo0bq8x3yOeOO+5Qe8LDw1VmGj6aNm2aykyD2L5SU1NV9t133+WY3XfffWrP/fffn+PPExEZPny4q32hzvcE+7Zt26o9y5YtU9n58+et1fS/mAbWJk+enOd1wC7TyeCjRo1SWYcOHVRmeg/0PUG8TJkyruro1auXykwngR87dsyx9j3VXkQkOTnZ1c9EwVOyZEnHumfPnmpPmzZtXF3rs88+U1liYqJj7eaUceRfLVu2VNmUKVNcvdb0UJ2lS5c61ldeeaXaM3bsWFfX37t3r6t9oYpPNgAAAABYQbMBAAAAwAqaDQAAAABW0GwAAAAAsCLfDIi7GcIxnTJuGo40DSHWrFnTr7pM13r++edVlpWV5df1/WUahjNlcKdZs2Yqe+qppxxr06Ci6eR1Nw8GcCsyMlJl7dq1U9mrr76qMt/hSxPTMHt6errL6pDXLly4oDLTgzNM/+zXrFmjMn9PGjc5c+aMymbNmuVYL1y4MGA/D8HF9PCB9957z7Hu3Lmzq2uZHnJiOv2ZgfCCxfQ7uGzZsipbuXKlyhYsWKAy34fA3HXXXa6ub3oYxtGjR1WG/+KTDQAAAABW0GwAAAAAsIJmAwAAAIAV+WZm4/DhwyqLiopyrIsXL6721KtXz9X1v/32W5WtWrXKsZ47d67aYzqoJa/nM2Cf6fu+sbGxOb7uscceU5npu+v+Mn1H9cYbb1SZm+/er1ixQmVTp05V2fLly90Vhzz3008/qcx0wOff/vY3lZkOxHJjxowZKvvXv/6lsi1btqjM9N1phKarrrpKZW5mNPbs2aMytwe5oWAxzeCYfveZMt/5DBGRe+65x7E2HYR78uRJlb3//vsqM/0uxX/xyQYAAAAAK2g2AAAAAFhBswEAAADACpoNAAAAAFbkmwHx+Ph4lfkO75gGY3///XeVffjhhyozDflkZmb+iQoB7ZFHHvG6BBEx/3vw9ddfO9ZDhw5VezjAL/h98803rjIgr1x77bUqGzFiRI6v2717t8ruuOOOgNSE4FexYkVX+0wH7C1ZskRlzZs3z/Faffv2VZnv71bkjE82AAAAAFhBswEAAADACpoNAAAAAFbQbAAAAACwIizbzdHDIhIWFma7FgQhl7dPrtm+/+Li4lSWkJDgWPfu3dtqDaaTcs+dO6ey1atXq+zdd99V2bZt2wJTWD6WV/efCO+BMCso74GBlJiYqLJu3brl+Drf91wRTmbOSSjdf8OGDVPZK6+84uq1pvpPnDjhWL/55ptqzwsvvKCy8+fPu/qZocDt/ccnGwAAAACsoNkAAAAAYAXNBgAAAAAraDYAAAAAWJFvThAHvLR161aVDRo0yLH+8ccf1Z6///3vKitXrpzK5s6dqzLfE03nzZun9hw+fFhlAJBf1KlTR2URERGuXuv7YItly5YFpCYUTDNmzFBZsWLFVPb000+rbNOmTSqbP3++Y/3aa6/lojr8ET7ZAAAAAGAFzQYAAAAAK2g2AAAAAFhBswEAAADACk4QR66E0umlyH84QRxeC/X3wBdffFFlI0aMUNm+fftU1q5dO8d6165dgSssRIT6/QdvcYI4AAAAAE/RbAAAAACwgmYDAAAAgBXMbCBX+L4ovMTMBrwW6u+BrVq1UtmiRYtU1qlTJ5WZDjLFnxPq9x+8xcwGAAAAAE/RbAAAAACwgmYDAAAAgBU0GwAAAACsYEAcucJwGrzEgDi8xnsgvMT9By8xIA4AAADAUzQbAAAAAKyg2QAAAABgBc0GAAAAACtcD4gDAAAAwJ/BJxsAAAAArKDZAAAAAGAFzQYAAAAAK2g2AAAAAFhBswEAAADACpoNAAAAAFbQbAAAAACwgmYDAAAAgBU0GwAAAACs+H9EKpJ1ne6LPQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nSqedPha-qFY"
      },
      "source": [
        "# Preprocessing Step"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.cluster import KMeans\n",
        "from scipy.spatial import distance\n",
        "import numpy as np\n",
        "\n",
        "train_images_np = mnist_trainset.data.numpy()\n",
        "train_labels_np = mnist_trainset.targets.numpy()\n",
        "test_images_np = mnist_testset.data.numpy()\n",
        "test_labels_np = mnist_testset.targets.numpy()\n",
        "\n",
        "n_samples, nx, ny = train_images_np.shape\n",
        "train_images_flattened = train_images_np.reshape((n_samples, -1))\n",
        "\n",
        "\n",
        "n_clusters = 200\n",
        "kmeans = KMeans(n_clusters=n_clusters)\n",
        "kmeans.fit(train_images_flattened)\n",
        "\n",
        "selected_indices = []\n",
        "\n",
        "distances = kmeans.transform(train_images_flattened)\n",
        "\n",
        "for i in tqdm(range(n_clusters), desc=\"select sample\"):\n",
        "    indices_in_cluster = np.where(kmeans.labels_ == i)[0]\n",
        "    cluster_distances = distances[indices_in_cluster, i]\n",
        "    index_of_closest_in_cluster = np.argmin(cluster_distances)\n",
        "    original_index = indices_in_cluster[index_of_closest_in_cluster]\n",
        "    selected_indices.append(original_index)\n",
        "\n",
        "all_indices = np.arange(len(train_images_np))\n",
        "unlabeled_indices = np.setdiff1d(all_indices, selected_indices)\n",
        "\n",
        "train_x = train_images_np[selected_indices]\n",
        "train_y_raw = train_labels_np[selected_indices]\n",
        "\n",
        "train_unlabeled = train_images_np[unlabeled_indices]\n",
        "\n",
        "test_x = test_images_np\n",
        "test_y_raw = test_labels_np"
      ],
      "metadata": {
        "id": "zZ0mo3iVJb4u",
        "outputId": "d909af0c-e5ae-4aa3-c2e4-033bace3f9c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'tqdm' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3796528957.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_images_flattened\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdesc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"select sample\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m     \u001b[0mindices_in_cluster\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwhere\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkmeans\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mcluster_distances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindices_in_cluster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'tqdm' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iBDc-212-qFX"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def one_hot(y):\n",
        "  #For converting a numpy array of 0-9 into a one hot encoding of vectors of length 10\n",
        "  b = np.zeros((y.size, y.max() + 1))\n",
        "  b[np.arange(y.size), y] = 1\n",
        "  return b.astype(np.float32)\n",
        "\n",
        "train_y = one_hot(train_y_raw)\n",
        "test_y = one_hot(test_y_raw)\n",
        "\n",
        "train_x = np.expand_dims(train_x, 1).astype(np.float32)\n",
        "train_unlabeled = np.expand_dims(train_unlabeled, 1).astype(np.float32)\n",
        "test_x = np.expand_dims(test_x, 1).astype(np.float32)\n",
        "\n",
        "torch_train_x = torch.tensor(train_x, requires_grad=True).to(device)\n",
        "torch_train_y = torch.tensor(train_y).to(device)\n",
        "torch_test_x = torch.tensor(test_x, requires_grad=True).to(device)\n",
        "torch_test_y = torch.tensor(test_y).to(device)\n",
        "torch_train_unlabeled = torch.tensor(train_unlabeled, requires_grad=True).to(device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HZ79cl-M-qFZ"
      },
      "source": [
        "# Defining Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZpwwGKaP-qFa"
      },
      "outputs": [],
      "source": [
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "\n",
        "class Backbone(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Backbone, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1,16,3)\n",
        "        self.conv2 = nn.Conv2d(16,16,3)\n",
        "        self.conv3 = nn.Conv2d(16,32,3)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(F.relu(self.conv1(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
        "        x = F.max_pool2d(F.relu(self.conv3(x)), 2)\n",
        "        x = torch.flatten(x, 1)\n",
        "        return x\n",
        "\n",
        "#defining model head\n",
        "class Head(nn.Module):\n",
        "    def __init__(self, n_class=10):\n",
        "        super(Head, self).__init__()\n",
        "        self.fc1 = nn.Linear(32, 32)\n",
        "        self.fc2 = nn.Linear(32, 16)\n",
        "        self.fc3 = nn.Linear(16, n_class)\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Model, self).__init__()\n",
        "        self.backbone = Backbone()\n",
        "        self.head = Head()\n",
        "\n",
        "        if torch.cuda.is_available():\n",
        "            self.cuda()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.backbone(x)\n",
        "        x = self.head(x)\n",
        "        return x\n",
        "\n",
        "model_baseline = Model()\n",
        "print(model_baseline(torch_train_x[:1]).shape)\n",
        "model_baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gtO78pvh-qFb"
      },
      "source": [
        "# Train without unlabeled data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZTQ90LtY-qFb"
      },
      "outputs": [],
      "source": [
        "def supervised_train(model):\n",
        "\n",
        "    batch_size = 32\n",
        "    lr = 0.001\n",
        "    momentum = 0.9\n",
        "    num_epochs = 2500\n",
        "\n",
        "    #defining a stocastic gradient descent optimizer\n",
        "    optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "\n",
        "    #defining loss function\n",
        "    loss_fn = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    train_hist = []\n",
        "    test_hist = []\n",
        "    test_accuracy = []\n",
        "\n",
        "    for epoch in tqdm(range(num_epochs)):\n",
        "\n",
        "        #iterating over all batches\n",
        "        for i in range(int(len(train_x)/batch_size)-1):\n",
        "\n",
        "            #Put the model in training mode, so that things like dropout work\n",
        "            model.train(True)\n",
        "\n",
        "\n",
        "            # Zero gradients for the optimizer\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "\n",
        "            #extracting X and y values from the batch\n",
        "            X = torch_train_x[i*batch_size: (i+1)*batch_size]\n",
        "            y = torch_train_y[i*batch_size: (i+1)*batch_size]\n",
        "\n",
        "            # Make predictions for this batch\n",
        "            y_pred = model(X)\n",
        "\n",
        "            #compute gradients with the loss function\n",
        "            loss = loss_fn(y_pred, y)\n",
        "            loss.backward()\n",
        "\n",
        "\n",
        "            # Adjust learning weights\n",
        "            optimizer.step()\n",
        "\n",
        "        with torch.no_grad():\n",
        "\n",
        "            #Disable things like dropout, if they exist\n",
        "            model.train(False)\n",
        "\n",
        "            #calculating epoch training and test loss\n",
        "            train_loss = loss_fn(model(torch_train_x), torch_train_y).cpu().numpy()\n",
        "            y_pred_test = model(torch_test_x)\n",
        "            test_loss = loss_fn(y_pred_test, torch_test_y).cpu().numpy()\n",
        "\n",
        "            train_hist.append(train_loss) # use train loss to plot\n",
        "            test_hist.append(test_loss) # use test loss to plot\n",
        "\n",
        "            #computing test accuracy\n",
        "            matches = np.equal(np.argmax(y_pred_test.cpu().numpy(), axis=1), np.argmax(torch_test_y.cpu().numpy(), axis=1))\n",
        "            test_accuracy.append(np.mean(matches))\n",
        "\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.plot(train_hist, label = 'train loss')\n",
        "    plt.plot(test_hist, label = 'test loss')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "    plt.plot(test_accuracy, label = 'test accuracy')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    maxacc = np.max(test_accuracy)\n",
        "    print('max accuracy: {}'.format(maxacc))\n",
        "\n",
        "    return maxacc\n",
        "\n",
        "supervised_maxacc = supervised_train(model_baseline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1zsOqZn-qFc"
      },
      "source": [
        "# Data Augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPSecXqN-qFd"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torchvision.transforms as T\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class Augment:\n",
        "\n",
        "   def __init__(self):\n",
        "\n",
        "       blur = T.GaussianBlur()\n",
        "\n",
        "       self.train_transform = torch.nn.Sequential(\n",
        "           T.RandomAffine(),\n",
        "           T.RandomPerspective(),\n",
        "           T.RandomPerspective(),\n",
        "           T.RandomPerspective(0.2,0.5),\n",
        "           T.RandomApply([blur],),\n",
        "           T.RandomApply([blur],)\n",
        "       )\n",
        "\n",
        "   def __call__(self, x):\n",
        "       return self.train_transform(x), self.train_transform(x)\n",
        "\n",
        "\"\"\"\n",
        "Generating Test Augmentation\n",
        "\"\"\"\n",
        "a = Augment()\n",
        "aug = a(torch_train_unlabled[0:100])\n",
        "\n",
        "i=1\n",
        "f, axarr = plt.subplots(2,2)\n",
        "#positive pair\n",
        "axarr[0,0].imshow(aug[0].cpu().detach().numpy()[i,0])\n",
        "axarr[0,1].imshow(aug[1].cpu().detach().numpy()[i,0])\n",
        "#another positive pair\n",
        "axarr[1,0].imshow(aug[0].cpu().detach().numpy()[i+1,0])\n",
        "axarr[1,1].imshow(aug[1].cpu().detach().numpy()[i+1,0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PYlS7OSU-qFd"
      },
      "source": [
        "# Defining Contrastive Loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kMYVohZj-qFe"
      },
      "outputs": [],
      "source": [
        "class ContrastiveLoss(nn.Module):\n",
        "   def __init__(self, batch_size, temperature=0.5):\n",
        "\n",
        "       super().__init__()\n",
        "       self.batch_size = batch_size\n",
        "       self.temperature = temperature\n",
        "       self.mask = (~torch.eye(batch_size * 2, batch_size * 2, dtype=bool)).float().to(device)\n",
        "\n",
        "   def calc_similarity_batch(self, a, b):\n",
        "       representations = torch.cat([a, b], dim=0)\n",
        "       return F.cosine_similarity(representations.unsqueeze(1), representations.unsqueeze(0), dim=2)\n",
        "\n",
        "   def forward(self, proj_1, proj_2):\n",
        "       batch_size = proj_1.shape[0]\n",
        "       z_i = F.normalize(proj_1, p=2, dim=1)\n",
        "       z_j = F.normalize(proj_2, p=2, dim=1)\n",
        "\n",
        "       similarity_matrix = self.calc_similarity_batch(z_i, z_j)\n",
        "\n",
        "       sim_ij = torch.diag(similarity_matrix, batch_size)\n",
        "       sim_ji = torch.diag(similarity_matrix, -batch_size)\n",
        "\n",
        "       positives = torch.cat([sim_ij, sim_ji], dim=0)\n",
        "\n",
        "       nominator = torch.exp(positives / self.temperature)\n",
        "\n",
        "       denominator = self.mask * torch.exp(similarity_matrix / self.temperature)\n",
        "\n",
        "       all_losses = -torch.log(nominator / torch.sum(denominator, dim=1))\n",
        "       loss = torch.sum(all_losses) / (2 * self.batch_size)\n",
        "       return loss\n",
        "\n",
        "loss = # use the above loss\n",
        "fake_proj_0, fake_proj_1 = a(torch_train_x)\n",
        "fake_proj_0 = fake_proj_0[:,0,:,0]\n",
        "fake_proj_1 = fake_proj_1[:,0,:,0]\n",
        "loss(fake_proj_0, fake_proj_1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fEGYlEKv-qFe"
      },
      "source": [
        "# Training on whole data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rw0nGjut-qFe"
      },
      "outputs": [],
      "source": [
        "from torch.optim.lr_scheduler import ExponentialLR\n",
        "\n",
        "model =\n",
        "model.train()\n",
        "\n",
        "#defining key hyperparameters\n",
        "batch_size = 512\n",
        "epoch_size =\n",
        "num_epochs = # more than 50\n",
        "patience = 5\n",
        "cutoff_ratio = 0.001\n",
        "\n",
        "#defining key learning functions\n",
        "optimizer = torch.optim.Adam(, lr=1e-3)\n",
        "num_examples =\n",
        "lossfn =\n",
        "augmentfn =\n",
        "\n",
        "#for book keeping\n",
        "loss_hist = []\n",
        "improvement_hist = []\n",
        "schedule_hist = []\n",
        "\n",
        "#for exponentially decreasing learning rate\n",
        "scheduler = ExponentialLR(, gamma = 0.95)\n",
        "\n",
        "#for early stopping\n",
        "patience_count = 0\n",
        "\n",
        "#Training Loop\n",
        "avg_loss = 1e10\n",
        "for i in range(num_epochs):\n",
        "\n",
        "    print('epoch {}/{}'.format(i,num_epochs))\n",
        "\n",
        "    total_loss = 0\n",
        "    loss_change = 0\n",
        "\n",
        "    for j in tqdm(range(epoch_size)):\n",
        "\n",
        "        #getting random batch\n",
        "        X = torch_train_unlabled[j*batch_size: (j+1)*batch_size]\n",
        "\n",
        "        #creating pairs of augmented batches\n",
        "        X_aug_i, X_aug_j =\n",
        "\n",
        "        #ensuring gradients are zero\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        #passing through the model\n",
        "        z_i = model()\n",
        "        z_j = model()\n",
        "\n",
        "        #calculating loss on the model embeddings, and computing gradients\n",
        "        loss =\n",
        "        loss.backward()\n",
        "\n",
        "        # Adjust learning weights\n",
        "        optimizer.step()\n",
        "\n",
        "        if True:\n",
        "            z_i = model(X_aug_i)\n",
        "            z_j = model(X_aug_j)\n",
        "\n",
        "            #calculating new loss value\n",
        "            new_loss = lossfn(z_i, z_j)\n",
        "\n",
        "            loss_change += new_loss.cpu().detach().numpy() - loss.cpu().detach().numpy()\n",
        "\n",
        "        total_loss +=\n",
        "\n",
        "        #step learning rate scheduler\n",
        "        schedule_hist.append(scheduler.get_last_lr())\n",
        "\n",
        "    #########################\n",
        "    # update scheduler here #\n",
        "    #########################\n",
        "\n",
        "    #calculating percentage loss reduction\n",
        "    new_avg_loss = total_loss/epoch_size\n",
        "    per_loss_reduction = (avg_loss-new_avg_loss)/avg_loss\n",
        "    print('Percentage Loss Reduction: {}'.format(per_loss_reduction))\n",
        "\n",
        "    #deciding to stop if loss is not decreasing fast enough\n",
        "    if per_loss_reduction < cutoff_ratio:\n",
        "        patience_count+=1\n",
        "        print('patience counter: {}'.format(patience_count))\n",
        "        if patience_count > patience:\n",
        "            break\n",
        "    else:\n",
        "        patience_count = 0\n",
        "\n",
        "    #setting new loss as previous loss\n",
        "    avg_loss = new_avg_loss\n",
        "\n",
        "    #book keeping\n",
        "    avg_improvement = loss_change/epoch_size\n",
        "    loss_hist.append(avg_loss)\n",
        "    improvement_hist.append(avg_improvement)\n",
        "    print('Average Loss: {}'.format(avg_loss))\n",
        "    print('Average Loss change (if calculated): {}'.format(avg_improvement))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhMQRx1g-qFf"
      },
      "outputs": [],
      "source": [
        "plt.plot(schedule_hist, label='learning rate')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "plt.plot(loss_hist, label = 'loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
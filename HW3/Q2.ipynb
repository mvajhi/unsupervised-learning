{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"recap\"></a>\n",
    "## Quick recap\n",
    "\n",
    "### Normalizing flows\n",
    "\n",
    "Normalizing flows allow to transform a probability distribution, through a series of *change of variable*. If we start with a random vector $\\mathbf{z}_0$ with distribution $q_0$, we can apply a series of mappings $f_i$, $i \\in 1,\\cdots,k$ with $k\\in\\mathcal{N}^{+}$ and obtain a normalizing flow. If we apply $k$ normalizing flows, the distribution of $\\mathbf{z}_k\\sim q_k(\\mathbf{z}_k)$ in log-probability will be given by\n",
    "\n",
    "$$\n",
    "\\text{log} q_K(\\mathbf{z}_k) = \\text{log} q_0(\\mathbf{z}_0) - \\sum_{i=1}^{k} \\text{log} \\left|\\text{det}\\frac{\\delta f_i}{\\delta\\mathbf{z}_{i-1}}\\right| \n",
    "\\tag{1}\n",
    "$$\n",
    "\n",
    "Of course, we can perform any amount of combined transformations.\n",
    "\n",
    "### PyTorch distributions\n",
    "\n",
    "We still rely on the novel [PyTorch distributions module](https://pytorch.org/docs/stable/_modules/torch/distributions/), which is defined in `torch.distributions`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.distributions as distrib\n",
    "import torch.distributions.transforms as transform\n",
    "import matplotlib.animation as animation\n",
    "matplotlib.rcParams['animation.ffmpeg_path'] = '/usr/local/bin/ffmpeg'\n",
    "from IPython.display import HTML\n",
    "# Imports for plotting\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "# Define grids of points (for later plots)\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "x = np.linspace(-4, 4, 1000)\n",
    "z = np.array(np.meshgrid(x, x)).transpose(1, 2, 0)\n",
    "z = np.reshape(z, [z.shape[0] * z.shape[1], -1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing normalizing flows\n",
    "\n",
    "The main interest in normalizing flows is that we could optimize the parameters of these flow in order to fit complex and rich probability distributions. In order to perform *inference*, we had to deal with the fact that the `Transform` object is not inherently parametric. To do so, we define our own `Flow` class which can be seen both as a `Transform` and also a `Module`that can be optmized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flow(transform.Transform, nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        transform.Transform.__init__(self)\n",
    "        nn.Module.__init__(self)\n",
    "    \n",
    "    def init_parameters(self):\n",
    "        for param in self.parameters():\n",
    "            param.data.uniform_(-0.01, 0.01)\n",
    "            \n",
    "    def __hash__(self):\n",
    "        return nn.Module.__hash__(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on this minimal class, we defined a wide variety of flows in the previous tutorials, but we will here simply reuse the *planar* and *radial* flows. Therefore, we redefine here the `PlanarFlow` and `RadialFlow` classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlanarFlow(Flow):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(PlanarFlow, self).__init__()\n",
    "        self.weight = nn.Parameter(torch.Tensor(1, dim))\n",
    "        self.scale = nn.Parameter(torch.Tensor(1, dim))\n",
    "        self.bias = nn.Parameter(torch.Tensor(1))\n",
    "        self.init_parameters()\n",
    "\n",
    "    def _call(self, z):\n",
    "        f_z = F.linear(z, self.weight, self.bias)\n",
    "        return z + self.scale * torch.tanh(f_z)\n",
    "\n",
    "    def log_abs_det_jacobian(self, z):\n",
    "        f_z = F.linear(z, self.weight, self.bias)\n",
    "        psi = (1 - torch.tanh(f_z) ** 2) * self.weight\n",
    "        det_grad = 1 + torch.mm(psi, self.scale.t())\n",
    "        return torch.log(det_grad.abs() + 1e-9)\n",
    "    \n",
    "class RadialFlow(Flow):\n",
    "\n",
    "    def __init__(self, dim):\n",
    "        super(RadialFlow, self).__init__()\n",
    "        self.z0 = nn.Parameter(torch.Tensor(1, dim))\n",
    "        self.alpha = nn.Parameter(torch.Tensor(1))\n",
    "        self.beta = nn.Parameter(torch.Tensor(1))\n",
    "        self.dim = dim\n",
    "        self.init_parameters()\n",
    "\n",
    "    def _call(self, z):\n",
    "        r = torch.norm(z - self.z0, dim=1).unsqueeze(1)\n",
    "        h = 1 / (self.alpha + r)\n",
    "        return z + (self.beta * h * (z - self.z0))\n",
    "\n",
    "    def log_abs_det_jacobian(self, z):\n",
    "        r = torch.norm(z - self.z0, dim=1).unsqueeze(1)\n",
    "        h = 1 / (self.alpha + r)\n",
    "        hp = - 1 / (self.alpha + r) ** 2\n",
    "        bh = self.beta * h\n",
    "        det_grad = ((1 + bh) ** self.dim - 1) * (1 + bh + self.beta * hp * r)\n",
    "        return torch.log(det_grad.abs() + 1e-9)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now in order to define a sequence of such flows, we defined a `NormalizingFlow` class, which is responsible for applying a series of flows and recording their determinant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NormalizingFlow(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, blocks, flow_length, density):\n",
    "        super().__init__()\n",
    "        biject = []\n",
    "        for f in range(flow_length):\n",
    "            for b_flow in blocks:\n",
    "                biject.append(b_flow(dim))\n",
    "        self.transforms = transform.ComposeTransform(biject)\n",
    "        self.bijectors = nn.ModuleList(biject)\n",
    "        self.base_density = density\n",
    "        self.final_density = distrib.TransformedDistribution(density, self.transforms)\n",
    "        self.log_det = []\n",
    "\n",
    "    def forward(self, z):\n",
    "        self.log_det = []\n",
    "        # Applies series of flows\n",
    "        for b in range(len(self.bijectors)):\n",
    "            self.log_det.append(self.bijectors[b].log_abs_det_jacobian(z))\n",
    "            z = self.bijectors[b](z)\n",
    "        return z, self.log_det"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimalist VAE implementation\n",
    "\n",
    "As we have seen, VAEs can be simply implemented by decomposing the above series of operations into an `encoder` which represents the distribution $q_\\phi(\\mathbf{z}\\vert\\mathbf{x})$, from which we will sample some values $\\tilde{\\mathbf{z}}$ (using the reparametrization trick) and compute the Kullback-Leibler (KL) divergence. Then, we use these values as input to a `decoder` which represents the distribution $p_\\theta(\\mathbf{x}\\vert\\mathbf{z})$ so that we can produce a reconstruction $\\tilde{\\mathbf{x}}$ and compute the reconstruction error. This process is implemented in the following `VAE` class.\n",
    "\n",
    "Note that we purposedly rely on an implementation of the `encode` function where the `encoder` first produces an intermediate representation of size `encoder_dims`. Then, this representation goes through two separate functions for encoding $\\mathbf{\\mu}$ and $\\mathbf{\\sigma}$. This provides a clearer implementation but also the added bonus that we can ensure that $\\mathbf{\\sigma} > 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, encoder_dims, latent_dims):\n",
    "        super().__init__()\n",
    "        self.encoder = \n",
    "        self.decoder = \n",
    "        self.latent_dims = \n",
    "        self.encoder_dims = \n",
    "        self.mu = \n",
    "        self.sigma = nn.Sequential(\n",
    "            nn.Linear(encoder_dims, latent_dims),\n",
    "            nn.Softplus(),\n",
    "            nn.Hardtanh(min_val=1e-4, max_val=5.))\n",
    "        self.apply(self.init_parameters)\n",
    "    \n",
    "    def init_parameters(self, m):\n",
    "        if type(m) == nn.Linear or type(m) == nn.Conv2d:\n",
    "            torch.nn.init.xavier_uniform_(m.weight)\n",
    "            m.bias.data.fill_(0.01)\n",
    "        \n",
    "    def encode(self, x):\n",
    "        x = \n",
    "        mu = \n",
    "        sigma = \n",
    "        return mu, sigma\n",
    "    \n",
    "    def decode(self, z):\n",
    "        return \n",
    "\n",
    "    def forward(self, x):\n",
    "        # Encode the inputs\n",
    "        z_params = \n",
    "        # Obtain latent samples and latent loss\n",
    "        z_tilde, kl_div = \n",
    "        # Decode the samples\n",
    "        x_tilde = \n",
    "        return x_tilde, kl_div\n",
    "    \n",
    "    def latent(self, x, z_params):\n",
    "        n_batch = x.size(0)\n",
    "        # Retrieve mean and var\n",
    "        mu, sigma = z_params\n",
    "        # Re-parametrize\n",
    "        q = distrib.Normal(torch.zeros(mu.shape[1]), torch.ones(sigma.shape[1]))\n",
    "        z = (sigma * q.sample((n_batch, ))) + mu\n",
    "        # Compute KL divergence\n",
    "        kl_div = -0.5 * torch.sum(1 + sigma - mu.pow(2) - sigma.exp())\n",
    "        kl_div = kl_div / n_batch\n",
    "        return z, kl_div"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the interesting aspect of VAEs is that we can define any parametric function as `encoder` and `decoder`, as long as we can optimize them. Here, we will rely on simple feed-forward neural networks, but these can be largely more complex (with limitations that we will discuss later in the tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_encoder_decoder(nin, n_latent = 16, n_hidden = 512, n_classes = 1):\n",
    "    # Encoder network\n",
    "    encoder = nn.Sequential()\n",
    "    # Decoder network\n",
    "    decoder = nn.Sequential()\n",
    "    return encoder, decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the reconstruction error\n",
    "\n",
    "In the definition of the `VAE` class, we directly included the computation of the $D_{KL}$ term to regularize our latent space. However, remember that the complete loss of equation (4) also contains a *reconstruction loss* which compares our reconstructed output to the original data. \n",
    "\n",
    "While there are several options to compare the error between two elements, there are usually two preferred choices among the generative literature depending on how we consider our problem\n",
    "1. If we consider each dimension (pixel) to be a binary unit (following a Bernoulli distribution), we can rely on the `binary cross entropy` between the two distributions\n",
    "2. If we turn our problem to a set of classifications, where each dimension can belong to a given set of *intensity classes*, then we can compute the `multinomial loss` between the two distributions\n",
    "\n",
    "In the following, we define both error functions and regroup them in the `reconstruction_loss` call (depending on the `num_classes` considered). However, as the `multinomial loss` requires a large computational overhead, and for the sake of simplicity, we will train all our first models by relying on the `binary cross entropy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binary_loss(x_tilde, x):\n",
    "    return F.binary_cross_entropy(x_tilde, x, reduction='none').sum(dim = 0)\n",
    "\n",
    "def multinomial_loss(x_logit, x):\n",
    "    batch_size = x.shape[0]\n",
    "    # Reshape input\n",
    "    x_logit = x_logit.view(batch_size, num_classes, x.shape[1], x.shape[2], x.shape[3])\n",
    "    # Take softmax\n",
    "    x_logit = F.log_softmax(x_logit, 1)\n",
    "    # make integer class labels\n",
    "    target = (x * (num_classes - 1)).long()\n",
    "    # computes cross entropy over all dimensions separately:\n",
    "    ce = F.nll_loss(x_logit, target, weight=None, reduction='none')\n",
    "    return ce.sum(dim = 0)*100\n",
    "\n",
    "def reconstruction_loss(x_tilde, x, num_classes=1, average=True):\n",
    "    if (num_classes == 1):\n",
    "        loss = binary_loss(x_tilde, x.view(x.size(0), -1))\n",
    "    else:\n",
    "        loss = multinomial_loss(x_tilde, x)\n",
    "    if (average):\n",
    "        loss = loss.sum() / x.size(0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing a VAE on a real dataset\n",
    "\n",
    "For this tutorial, we are going to take a quick shot at a real-life problem by trying to train our VAEs on the `FashionMNIST` dataset. This dataset can be natively used in PyTorch by relying on the `torchvision.datasets` classes as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "tens_t = transforms.ToTensor()\n",
    "train_dset = datasets.FashionMNIST('./data', train=True, download=True, transform=tens_t)\n",
    "train_loader = torch.utils.data.DataLoader(train_dset, batch_size=batch_size, shuffle=True)\n",
    "test_dset = datasets.FashionMNIST('./data', train=False, transform=tens_t)\n",
    "test_loader = torch.utils.data.DataLoader(test_dset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `FashionMNIST` dataset is composed of simple 28x28 black and white images of different items of clothings (such as shoes, bags, pants and shirts). We put a simple function here to display one batch of the test set (note that we keep a fixed batch from the test set in order to evaluate the different variations that we will try in this tutorial)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_batch(batch, nslices=8):\n",
    "    # Create one big image for plot\n",
    "    img = np.zeros(((batch.shape[2] + 1) * nslices, (batch.shape[3] + 1) * nslices))\n",
    "    for b in range(batch.shape[0]):\n",
    "        row = int(b / nslices); col = int(b % nslices)\n",
    "        r_p = row * batch.shape[2] + row; c_p = col * batch.shape[3] + col\n",
    "        img[r_p:(r_p+batch.shape[2]),c_p:(c_p+batch.shape[3])] = torch.sum(batch[b], 0)\n",
    "    im = plt.imshow(img, cmap='Greys', interpolation='nearest'),\n",
    "    return im\n",
    "# Select a random set of fixed data\n",
    "fixed_batch, fixed_targets = next(iter(test_loader))\n",
    "plt.figure(figsize=(10, 10))\n",
    "plot_batch(fixed_batch);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now based on our proposed implementation, the optimization aspects are defined in a very usual way"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Bernoulli or Multinomial loss\n",
    "num_classes = 1\n",
    "# Number of hidden and latent\n",
    "n_hidden = 512\n",
    "n_latent = 2\n",
    "# Compute input dimensionality\n",
    "nin = fixed_batch.shape[2] * fixed_batch.shape[3]\n",
    "# Construct encoder and decoder\n",
    "encoder, decoder = \n",
    "# Build the VAE model\n",
    "model = \n",
    "# Create optimizer algorithm\n",
    "optimizer = \n",
    "# Add learning rate scheduler\n",
    "scheduler = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all that is left to do is train the model. We define here a `train_vae` function that we will reuse along the future implementations and variations of VAEs and flows. Note that this function is set to run for only a very few number of `epochs` and also most importantly, *only considers a subsample of the full dataset at each epoch*. This option is just here so that you can test the different models very quickly on any CPU or laptop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, optimizer, scheduler, train_loader, fixed_batch, model_name='basic', epochs=50, plot_it=1, subsample=5000, flatten=True):\n",
    "    # Losses curves\n",
    "    losses = torch.zeros(epochs, 2)\n",
    "    # Beta-warmup\n",
    "    beta = 0\n",
    "    # Plotting\n",
    "    ims = []\n",
    "    fig = plt.figure(figsize=(10, 10))\n",
    "    # Main optimization loop\n",
    "    for it in range(epochs):\n",
    "        it_loss = torch.Tensor([2])\n",
    "        # Update our beta\n",
    "        beta = 1. * (it / float(epochs))\n",
    "        n_batch = 0.\n",
    "        # Evaluate loss and backprop\n",
    "        for batch_idx, (x, _) in enumerate(train_loader):\n",
    "            if (batch_idx * batch_size) > subsample:\n",
    "                break\n",
    "            # Flatten input data\n",
    "            if (flatten):\n",
    "                x = x.view(-1, nin)\n",
    "            # Pass through VAE\n",
    "            x_tilde, loss_latent = \n",
    "            # Compute reconstruction loss\n",
    "            loss_recons = \n",
    "            # Evaluate loss and backprop\n",
    "            loss = loss_recons + (beta * loss_latent)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "            losses[it, 0] += loss_recons.item()\n",
    "            losses[it, 1] += loss_latent.item()\n",
    "            n_batch += 1.\n",
    "        losses[it, :] /= n_batch\n",
    "        if (it % plot_it == 0):\n",
    "            # Encode our fixed batch\n",
    "            samples = fixed_batch\n",
    "            if (flatten):\n",
    "                samples = fixed_batch.view(-1, nin)\n",
    "            x_tilde, _ = model(samples)\n",
    "            if (num_classes > 1):\n",
    "                # Find largest class logit\n",
    "                tmp = x_tilde.view(-1, num_classes, *x[0].shape[1:]).max(dim=1)[1]\n",
    "                x_tilde = tmp.float() / (num_classes - 1.)\n",
    "            ims.append(plot_batch(x_tilde.detach().view_as(fixed_batch)))\n",
    "            plt.title('Iter.%i'%(it), fontsize=15);\n",
    "    # Generate our animation\n",
    "    anim = animation.ArtistAnimation(fig, ims, interval=50, repeat_delay=1000)\n",
    "    HTML(anim.to_html5_video())\n",
    "    anim.save(\"vae_\" + model_name + \".mp4\")\n",
    "    return losses\n",
    "            \n",
    "# Launch our optimization\n",
    "losses_kld = train_vae(model, optimizer, scheduler, train_loader, fixed_batch, model_name='basic', epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating generative models\n",
    "\n",
    "In order to evaluate our upcoming generative models, we will rely on the computation of the Negative Log-Likelihood. This code for the following `evaluate_nll_bpd` is inspired by the [Sylvester flow repository](https://github.com/riannevdberg/sylvester-flows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import logsumexp\n",
    "\n",
    "def evaluate_nll_bpd(data_loader, model, batch = 500, R = 5):\n",
    "    model.eval()\n",
    "    # Set of likelihood tests\n",
    "    likelihood_test = []\n",
    "    # Go through dataset\n",
    "    for batch_idx, (x, _) in enumerate(data_loader):\n",
    "        for j in range(x.shape[0]):\n",
    "            a = []\n",
    "            for r in range(0, R):\n",
    "                cur_x = x[j].unsqueeze(0)\n",
    "                # Repeat it as batch\n",
    "                x = cur_x.expand(batch, *cur_x.size()[1:]).contiguous()\n",
    "                x = x.view(batch, -1)\n",
    "                x_tilde, kl_div = model(x)\n",
    "                rec = reconstruction_loss(x_tilde, x, average=False)\n",
    "                a_tmp = (rec + kl_div)\n",
    "                a.append(- a_tmp.cpu().data.numpy())\n",
    "            # calculate max\n",
    "            a = np.asarray(a)\n",
    "            a = np.reshape(a, (a.shape[0] * a.shape[1], 1))\n",
    "            likelihood_x = logsumexp(a)\n",
    "            likelihood_test.append(likelihood_x - np.log(len(a)))\n",
    "    likelihood_test = np.array(likelihood_test)\n",
    "    nll = - np.mean(likelihood_test)\n",
    "    # Compute the bits per dim (but irrelevant for binary data)\n",
    "    bpd = nll / (np.prod(nin) * np.log(2.))\n",
    "    return nll, bpd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can evaluate our VAE model more formally as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot final loss\n",
    "plt.figure()\n",
    "plt.plot(losses_kld[:, 0].numpy());\n",
    "# Evaluate log-likelihood and bits per dim\n",
    "nll, _ = evaluate_nll_bpd(test_loader, model)\n",
    "print('Negative Log-Likelihood : ' + str(nll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"vae\"></a>\n",
    "## Normalizing flows and VAEs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flows as posterior\n",
    "\n",
    "In this first implementation of VAEs augmented with normalizing flows, we simply add a flow after the prior sampling. This is implemented in the following `VAENormalizingFlow` class. Note that the computation of different parts of the latent regularizations and the log determinants is performed explicitly here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAENormalizingFlow(VAE):\n",
    "    \n",
    "    def __init__(self, encoder, decoder, flow, encoder_dims, latent_dims):\n",
    "        super(VAENormalizingFlow, self).__init__(encoder, decoder, encoder_dims, latent_dims)\n",
    "        self.flow = flow\n",
    "\n",
    "    def latent(self, x, z_params):\n",
    "        n_batch = x.size(0)\n",
    "        # Retrieve set of parameters\n",
    "        mu, sigma = z_params\n",
    "        # Re-parametrize a Normal distribution\n",
    "        q = distrib.Normal(torch.zeros(mu.shape[1]), torch.ones(sigma.shape[1]))\n",
    "        # Obtain our first set of latent points\n",
    "        z_0 = (sigma * q.sample((n_batch, ))) + mu\n",
    "        # Complexify posterior with flows\n",
    "        z_k, list_ladj = self.flow(z_0)\n",
    "        # ln p(z_k) \n",
    "        log_p_zk = -0.5 * z_k * z_k\n",
    "        # ln q(z_0)\n",
    "        log_q_z0 = -0.5 * (sigma.log() + (z_0 - mu) * (z_0 - mu) * sigma.reciprocal())\n",
    "        #  ln q(z_0) - ln p(z_k)\n",
    "        logs = (log_q_z0 - log_p_zk).sum()\n",
    "        # Add log determinants\n",
    "        ladj = torch.cat(list_ladj)\n",
    "        # ln q(z_0) - ln p(z_k) - sum[log det]\n",
    "        logs -= torch.sum(ladj)\n",
    "        return z_k, (logs / float(n_batch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this model behaves almost exactly like the Vanilla `VAE`. However, we now complexify the latent distribution with a given `flow` and then replace the KL divergence with the regularization based on the variational free energy. Note also that we rely on the implementation of `Flow` from the previous tutorial, where each flow optimizes its own parameters. Therefore, we can simply optimize this model similarily as the previous one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Using Bernoulli or Multinomial loss\n",
    "num_classes = 1\n",
    "# Number of hidden and latent\n",
    "n_hidden = 512\n",
    "n_latent = 2\n",
    "# Our MLP blocks\n",
    "block_planar = [PlanarFlow]\n",
    "# Create normalizing flow\n",
    "flow = \n",
    "# Construct encoder and decoder\n",
    "encoder, decoder = \n",
    "# Create VAE with planar flows\n",
    "model_flow = \n",
    "# Create optimizer algorithm\n",
    "optimizer = \n",
    "# Add learning rate scheduler\n",
    "scheduler = \n",
    "# Launch our optimization\n",
    "losses_flow = "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can compare this improved VAE model with a normalizing flow to the original vanilla VAE on our log-likelihood criterion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "plt.figure()\n",
    "plt.plot(losses_flow[:, 0].numpy());\n",
    "# Evaluate log-likelihood and bits per dim\n",
    "nll, _ = evaluate_nll_bpd(test_loader, model_flow)\n",
    "print('Negative Log-Likelihood : ' + str(nll))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing the latent spaces of different models\n",
    "\n",
    "One of the key aspect in the difference between the vanilla VAE and the VAE with normalizing flow is the treatment of the latent space. Hence a good way of assessing the impact of our flows is to check how the flow process the latent points. Here, we perform some visualisations of the latent spaces obtained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import decomposition\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 6))\n",
    "models = {'vanilla':(model, ax1), 'planar indep.':(model_flow, ax2), 'planar params':(model_flow_p, ax3)}\n",
    "for name, (cur_model, ax) in models.items():\n",
    "    final_z = []\n",
    "    final_classes = []\n",
    "    for batch_idx, (x, c) in enumerate(train_loader):\n",
    "        if (x.shape[0] != 64):\n",
    "            break\n",
    "        x = (x.view(x.shape[0], -1) * 2) - 1\n",
    "        # Not exact but just consider mean for laziness\n",
    "        cur_mu, cur_sig, *params = cur_model.encode(x)\n",
    "        q = distrib.Normal(torch.zeros(cur_mu.shape[1]), torch.ones(cur_sig.shape[1]))\n",
    "        cur_z = (cur_sig * q.sample((64, ))) + cur_mu\n",
    "        if (hasattr(cur_model, 'flow')):\n",
    "            if (name == 'planar params'):\n",
    "                cur_model.flow.set_parameters(params[0])\n",
    "            cur_z, _ = cur_model.flow(cur_z)\n",
    "        final_z.append(cur_z.detach())\n",
    "        final_classes.append(c)\n",
    "    final_z = torch.cat(final_z)\n",
    "    final_classes = torch.cat(final_classes)\n",
    "    # Create PCA and apply it to our data\n",
    "    pca = # use PCA with 2 components here\n",
    "    # then apply the PCA to a value and call it z_pca\n",
    "    ax.scatter(z_pca[:, 0], z_pca[:, 1], c=final_classes, cmap=plt.cm.nipy_spectral, edgecolor='k')\n",
    "    ax.set_title(name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (Spyder)",
   "language": "python3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
